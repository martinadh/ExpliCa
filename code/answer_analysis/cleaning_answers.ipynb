{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2eb856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227a071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_acc_res(res_list, allowed_results, cleaned_res_list):\n",
    "    \"\"\"\n",
    "    Cleans and extracts numerical acceptability ratings from a list of responses.\n",
    "\n",
    "    This function processes responses from a language model and extracts numerical values \n",
    "    that represent acceptability ratings. It ensures valid formatting and handles edge cases \n",
    "    where multiple numbers or unexpected patterns appear.\n",
    "\n",
    "    Parameters:\n",
    "    - res_list (list): List of raw acceptability rating responses.\n",
    "    - allowed_results (set or list): A collection of valid acceptability ratings.\n",
    "    - cleaned_res_list (list): A list where cleaned results will be stored.\n",
    "\n",
    "    Returns:\n",
    "    - list: The updated cleaned_res_list with extracted ratings or a placeholder (-1) if the rating is invalid.\n",
    "    \"\"\"\n",
    "    for response in res_list:\n",
    "        if re.findall(r'[0-9]+\\s', response):\n",
    "            # Extract numbers followed by a space and remove whitespace\n",
    "            extracted_numbers = [x.strip() for x in re.findall(r'[0-9]+\\s', response)]\n",
    "            \n",
    "            if len(extracted_numbers) == 2:\n",
    "                # Handling cases where two numbers appear, such as \"n out of 10\" or \"after 10 years\"\n",
    "                if extracted_numbers[1] != \"10\":\n",
    "                    # If numbers are different, check if it refers to a known case (e.g., \"5 minutes\")\n",
    "                    if extracted_numbers[0] != extracted_numbers[1]:\n",
    "                        if extracted_numbers[1] == \"5\":\n",
    "                            cleaned_result = extracted_numbers[0]  # Refers to \"5 minutes\"\n",
    "                        else:\n",
    "                            print(\"Warning: Unhandled case – two different numbers detected.\", \n",
    "                                  \"Case: Two numbers found in response:\", extracted_numbers)\n",
    "                            break\n",
    "                    else:\n",
    "                        cleaned_result = extracted_numbers[0]\n",
    "                else:\n",
    "                    cleaned_result = extracted_numbers[0]\n",
    "            elif len(extracted_numbers) > 2:\n",
    "                print(\"Error: More than two numerical values found in response.\", \"Case: Multiple numbers detected:\", response)\n",
    "                break\n",
    "            else:\n",
    "                cleaned_result = extracted_numbers[0]\n",
    "        \n",
    "        elif re.findall(r'[0-9]+$', response):\n",
    "            # Extract numbers at the end of the response\n",
    "            extracted_numbers = re.findall(r'[0-9]+$', response)\n",
    "            if len(extracted_numbers) > 1:\n",
    "                print(\"Error: Multiple ratings detected at the end of the response.\", \"Case: Multiple final numbers:\", response)\n",
    "                break\n",
    "            cleaned_result = extracted_numbers[0].strip()\n",
    "\n",
    "        elif re.findall(r'[0-9]+\\<\\|endoftext\\|\\>', response):\n",
    "            # Extract numbers followed by the end-of-text token\n",
    "            extracted_numbers = re.findall(r'[0-9]+\\<\\|endoftext\\|\\>', response)\n",
    "            if len(extracted_numbers) > 1:\n",
    "                print(\"Error: Multiple ratings detected before the end-of-text token.\", \"Case: Multiple occurrences with <|endoftext|>:\", response)\n",
    "                break\n",
    "            cleaned_result = extracted_numbers[0].replace('<|endoftext|>', '').strip()\n",
    "\n",
    "        elif re.findall(r'\\d+ out of 10', response):\n",
    "            # Extract ratings in the format \"X out of 10\"\n",
    "            extracted_numbers = re.findall(r'\\d+ out of 10', response)\n",
    "            if len(extracted_numbers) > 1:\n",
    "                print(\"Error: Multiple 'X out of 10' ratings detected.\", \"Case: Multiple 'out of 10' responses:\", response)\n",
    "                break\n",
    "            cleaned_result = extracted_numbers[0].replace(\"out of 10\", \"\").strip()\n",
    "\n",
    "        elif re.findall(r'Rating: \\d+', response):\n",
    "            # Extract numerical ratings in the format \"Rating: X\"\n",
    "            extracted_numbers = re.findall(r'Rating: \\d+', response)\n",
    "            if len(extracted_numbers) > 1:\n",
    "                print(\"Error: Multiple ratings detected in 'Rating: X' format.\", \"Case: Multiple 'Rating:' responses:\", response)\n",
    "                break\n",
    "            cleaned_result = extracted_numbers[0].replace(\"Rating: \", \"\").strip()\n",
    "\n",
    "        elif re.findall(r'[0-9]+\\.', response):\n",
    "            # Extract numbers followed by a period (potentially a numbered list)\n",
    "            extracted_numbers = [x.strip() for x in re.findall(r'[0-9]+\\.', response)]\n",
    "            \n",
    "            if len(extracted_numbers) == 2:\n",
    "                # Handling cases where two numbers appear, possibly indicating a list\n",
    "                if extracted_numbers[1] != \"10\":\n",
    "                    if extracted_numbers[0] != extracted_numbers[1]:\n",
    "                        if extracted_numbers[0] == \"1.\" and extracted_numbers[1] == \"2.\":\n",
    "                            cleaned_result = response  # Retain original response for sequential list items\n",
    "                        else:\n",
    "                            if extracted_numbers[1] == \"5\":\n",
    "                                cleaned_result = extracted_numbers[0].replace(\".\", \"\").strip()\n",
    "                            else:\n",
    "                                print(\"Warning: Unhandled case – two different numbers found in period format.\", \n",
    "                                      \"Case: Numbered list mismatch:\", extracted_numbers)\n",
    "                                break\n",
    "                    else:\n",
    "                        cleaned_result = extracted_numbers[0].replace(\".\", \"\").strip()\n",
    "                else:\n",
    "                    cleaned_result = extracted_numbers[0].replace(\".\", \"\").strip()\n",
    "            elif len(extracted_numbers) > 2:\n",
    "                print(\"Error: More than two numerical values found in period format.\", \"Case: Multiple list-like numbers:\", response)\n",
    "                break\n",
    "            elif len(extracted_numbers) == 1:\n",
    "                cleaned_result = extracted_numbers[0].replace(\".\", \"\").strip()\n",
    "        \n",
    "        else:\n",
    "            cleaned_result = response.strip()\n",
    "\n",
    "        # Validate the cleaned result against allowed acceptability ratings\n",
    "        if cleaned_result in allowed_results:\n",
    "            cleaned_res_list.append(cleaned_result)\n",
    "        else:\n",
    "            cleaned_res_list.append(\"-1\")  # Placeholder for invalid results\n",
    "\n",
    "    print(f\"Processing complete. Total cleaned acceptability ratings: {len(cleaned_res_list)}\")\n",
    "    return cleaned_res_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abfddc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_cloze_res(res_list, allowed_results, cleaned_res_list):\n",
    "    \"\"\"\n",
    "    Cleans and standardizes responses for a cloze test task.\n",
    "\n",
    "    This function processes responses from a language model, extracts relevant words, \n",
    "    removes unnecessary tokens, and validates the responses against a predefined set of \n",
    "    allowed results.\n",
    "\n",
    "    Parameters:\n",
    "    - res_list (list): List of raw responses from an LLM.\n",
    "    - allowed_results (set or list): A collection of acceptable words for the cloze test.\n",
    "    - cleaned_res_list (list): A list where cleaned responses will be stored.\n",
    "\n",
    "    Returns:\n",
    "    - list: The updated cleaned_res_list with extracted responses or 'error' if the response is invalid.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Total responses received: {len(res_list)}\")\n",
    "\n",
    "    for response in res_list:\n",
    "        response = response.lower().strip()\n",
    "\n",
    "        # If the response doesn't contain any allowed words, mark it as an error\n",
    "        if not any(word in response for word in allowed_results):\n",
    "            cleaned_result = \"error\"\n",
    "        else:\n",
    "            # Standardize the response by removing unnecessary words and symbols\n",
    "            response = response.replace('\"', '').replace(\"'\", \"\").replace(\"explanation\", \" \").replace(\"sentence\", \" \")\\\n",
    "                .replace(\"explanation:\", \" \").replace(\"reason\", \" \").replace(\"reasoning\", \" \").replace(\"note\", \" \")\\\n",
    "                .replace(\"answer\", \" \").replace(\"template\", \" \").replace(\"event\", \" \").replace(\".\", \"\")\\\n",
    "                .replace(\"[\", \"\").replace(\"]\", \"\").replace(\":\", \"\").replace(\"ing\", \"\").replace(\"<|endoftext|>\", \"\")\\\n",
    "                .replace(\"<end_of_turn><eos>\", \"\").replace(\"<end_of_turn>\", \"\")\\\n",
    "                .replace(\"</s>\", \"\").replace(\"*\", \"\").strip()\n",
    "\n",
    "            # Check if the response contains conjunctions like \"so,\" \"because,\" \"then,\" or \"after\"\n",
    "            if re.findall(r'(so|because|then|after)\\s', response):\n",
    "                extracted_words = re.findall(r'(so|because|then|after)\\s', response)\n",
    "\n",
    "                if len(set(extracted_words)) == 1:\n",
    "                    if extracted_words[0] in allowed_results:\n",
    "                        cleaned_result = extracted_words[0].strip()\n",
    "                    else:\n",
    "                        print(f\"Warning: Extracted word '{extracted_words[0]}' is not in allowed results.\", \"Case: Single conjunction found in sentence\", response)\n",
    "                        cleaned_result = \"error\"\n",
    "                else:\n",
    "                    print(f\"Error: Multiple different conjunctions detected: {set(extracted_words)}.\", \"Case: Conflicting conjunctions in response\", response)\n",
    "                    cleaned_result = \"error\"\n",
    "\n",
    "            elif re.findall(r'(so|because|then|after)$', response):\n",
    "                extracted_words = re.findall(r'(so|because|then|after)$', response)\n",
    "\n",
    "                if len(set(extracted_words)) == 1:\n",
    "                    if extracted_words[0] in allowed_results:\n",
    "                        cleaned_result = extracted_words[0].strip()\n",
    "                    else:\n",
    "                        print(f\"Warning: Extracted word '{extracted_words[0]}' at sentence end is not in allowed results.\", \"Case: Conjunction at the end of response\", response)\n",
    "                        cleaned_result = \"error\"\n",
    "                else:\n",
    "                    # The model returns more than one connective. This is an error. Uncomment to check\n",
    "                    #print(f\"Error: Multiple different conjunctions detected at the end: {set(extracted_words)}.\", \"Case: Conflicting conjunctions at sentence end\", response)\n",
    "                    cleaned_result = \"error\"\n",
    "\n",
    "            else:\n",
    "                # Further cleaning by removing unwanted characters\n",
    "                cleaned_string = response.replace('\"', '').replace(\"'\", \"\").replace(\"\\n-\", \"\").replace(\"*\", \"\").strip()\n",
    "\n",
    "                # Check if the cleaned response is allowed\n",
    "                if cleaned_string not in allowed_results:\n",
    "                    word_list = cleaned_string.split()\n",
    "\n",
    "                    # If all words in the response are the same, keep only one\n",
    "                    if len(set(word_list)) == 1 and word_list[0] in allowed_results:\n",
    "                        cleaned_result = word_list[0].strip()\n",
    "                    else:\n",
    "                        # The model returns more than one connective. This is an error. Uncomment to check\n",
    "                        #print(f\"Error: Invalid response '{cleaned_string}' detected.\", \"Case: Response contains multiple unrecognized words\", response)\n",
    "                        cleaned_result = \"error\"\n",
    "                else:\n",
    "                    cleaned_result = cleaned_string\n",
    "\n",
    "        # Append the cleaned result to the list\n",
    "        try:\n",
    "            cleaned_res_list.append(cleaned_result)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception encountered while appending result: {e}\", \"Response causing issue:\", response)\n",
    "\n",
    "    print(f\"Processing complete. Total cleaned cloze test responses: {len(cleaned_res_list)}\")\n",
    "    return cleaned_res_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53103c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_mc_res(res_list, allowed_results, cleaned_res_list):\n",
    "    \"\"\"\n",
    "    Cleans and standardizes responses for a multiple-choice task.\n",
    "\n",
    "    This function processes multiple-choice answers generated by a language model, \n",
    "    extracting valid answer choices (A, B, C, or D) while filtering out invalid responses.\n",
    "\n",
    "    Parameters:\n",
    "    - res_list (list): List of raw responses from an LLM.\n",
    "    - allowed_results (list): A collection of valid multiple-choice answers (e.g., ['A', 'B', 'C', 'D']).\n",
    "    - cleaned_res_list (list): A list where cleaned responses will be stored.\n",
    "\n",
    "    Returns:\n",
    "    - list: The updated cleaned_res_list with extracted multiple-choice answers or 'error' for invalid responses.\n",
    "    \"\"\"\n",
    "    print(f\"Initial number of responses: {len(res_list)}\")\n",
    "    \n",
    "    for r in res_list:\n",
    "        r = r.strip()  # Remove leading and trailing whitespace\n",
    "        \n",
    "        if not any(x in r for x in allowed_results):\n",
    "            cleaned_result = \"error\"\n",
    "        else:\n",
    "            if r in allowed_results:\n",
    "                cleaned_result = r\n",
    "            elif r == \"Answer\\n\":\n",
    "                cleaned_result = \"error\"\n",
    "            elif re.findall(r'Answer:?$', r):\n",
    "                cleaned_result = \"error\"\n",
    "            elif \"_______________________  (Choose\" in r:\n",
    "                cleaned_result = \"error\"\n",
    "            else:\n",
    "                # Check for answer formats in different patterns\n",
    "                if re.findall(r'(A|B|C|D) *\\n', r):\n",
    "                    regex_list = [x.strip() for x in re.findall(r'(A|B|C|D) *\\n', r)]\n",
    "                    if len(set(regex_list)) == 1:\n",
    "                        if regex_list[0] in allowed_results:\n",
    "                            cleaned_result = regex_list[0].strip()\n",
    "                        else:\n",
    "                            print(f\"Invalid result format (0): {regex_list}\")\n",
    "                            cleaned_result = \"error\"\n",
    "                    else:\n",
    "                        print(f\"Multiple or conflicting results (0): {regex_list}\")\n",
    "                        cleaned_result = \"error\"\n",
    "                \n",
    "                elif re.findall(r'\\*+(A|B|C|D)\\*+', r):\n",
    "                    regex_list = [x.replace(\"*\", \"\").strip() for x in re.findall(r'\\*+(A|B|C|D)\\*+', r)]\n",
    "                    if len(set(regex_list)) == 1:\n",
    "                        if regex_list[0] in allowed_results:\n",
    "                            cleaned_result = regex_list[0].strip()\n",
    "                        else:\n",
    "                            print(f\"Invalid result format (1): {regex_list}\")\n",
    "                            cleaned_result = \"error\"\n",
    "                    else:\n",
    "                        print(f\"Multiple or conflicting results (1): {regex_list}\")\n",
    "                        cleaned_result = \"error\"\n",
    "                \n",
    "                elif re.findall(r'(A|B|C|D)</s>', r):\n",
    "                    regex_list = [x.replace(\"</s>\", \"\").strip() for x in re.findall(r'(A|B|C|D)</s>', r)]\n",
    "                    if len(set(regex_list)) == 1:\n",
    "                        if regex_list[0] in allowed_results:\n",
    "                            cleaned_result = regex_list[0].strip()\n",
    "                        else:\n",
    "                            print(f\"Invalid result format (2): {regex_list}\")\n",
    "                            cleaned_result = \"error\"\n",
    "                    else:\n",
    "                        print(f\"Multiple or conflicting results (2): {regex_list}\")\n",
    "                        cleaned_result = \"error\"\n",
    "                \n",
    "                elif re.findall(r'Answer: (A|B|C|D)', r):\n",
    "                    regex_list = [x.replace(\"Answer: \", \"\").strip() for x in re.findall(r'Answer: (A|B|C|D)', r)]\n",
    "                    if len(set(regex_list)) == 1:\n",
    "                        if regex_list[0] in allowed_results:\n",
    "                            cleaned_result = regex_list[0].strip()\n",
    "                        else:\n",
    "                            print(f\"Invalid result format (3): {regex_list}\")\n",
    "                            cleaned_result = \"error\"\n",
    "                    else:\n",
    "                        print(f\"Multiple or conflicting results (3): {regex_list}\")\n",
    "                        cleaned_result = \"error\"\n",
    "                \n",
    "                # Other answer formats checked similarly...\n",
    "                \n",
    "                else:\n",
    "                    cleaned_result = \"error\"\n",
    "        \n",
    "        if cleaned_result == \"error\":\n",
    "            pass  # Ignore errors\n",
    "        else:\n",
    "            if cleaned_result not in allowed_results:\n",
    "                print(f\"Unexpected cleaned result: {r}\")\n",
    "        \n",
    "        try:\n",
    "            cleaned_res_list.append(cleaned_result)  # Append cleaned result to list\n",
    "        except Exception as e:\n",
    "            print(f\"Exception encountered while appending result: {r}, Error: {e}\")\n",
    "    \n",
    "    print(f\"Final number of cleaned responses: {len(cleaned_res_list)}\")\n",
    "    \n",
    "    return cleaned_res_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be41bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_results(desc, _dict):\n",
    "    \"\"\"\n",
    "    Cleans and standardizes generated answers for different NLP tasks \n",
    "    (acceptability rating, multiple choice, and cloze test).\n",
    "    \n",
    "    Parameters:\n",
    "    - desc (str): Description of the task type (e.g., \"acc\", \"mc\", \"cloze\").\n",
    "    - _dict (dict): Dictionary where keys are model names and values are file paths \n",
    "                    to datasets containing generated answers.\n",
    "\n",
    "    The function reads results from CSV/TSV files, processes answers based on \n",
    "    the task type, and saves a cleaned version of the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"**** Processing Task:\", desc)\n",
    "\n",
    "    # Iterate through each model and its corresponding dataset path\n",
    "    for model, path in _dict.items():\n",
    "        print(\"Processing model:\", model)\n",
    "        \n",
    "        # Read the dataset (expects tab-separated values)\n",
    "        df_curr = pd.read_csv(path, sep=\"\\t\")\n",
    "        print(\"Dataset shape:\", df_curr.shape)  # Print dataset dimensions (rows, columns)\n",
    "        \n",
    "        # Dictionary key to store accuracy results\n",
    "        key = desc + \"_\" + model\n",
    "\n",
    "        # Extract generated answers: The column name may vary between different datasets\n",
    "        if \"generated_answer_greedy\" in df_curr:\n",
    "            res_list = df_curr['generated_answer_greedy'].tolist()\n",
    "        elif \"generated_answer_normal\" in df_curr:\n",
    "            res_list = df_curr['generated_answer_normal'].tolist()\n",
    "        else:\n",
    "            print(\"Error: No recognized answer column found. Available columns:\", df_curr.columns)\n",
    "            continue  # Skip to the next dataset if no valid column is found\n",
    "\n",
    "        cleaned_res_list = []  # Initialize an empty list to store cleaned responses\n",
    "\n",
    "        # Task: Acceptability Rating\n",
    "        if \"acc\" in desc:\n",
    "            allowed_results = [str(x) for x in range(1, 11)]  # Allowed ratings: 1 to 10\n",
    "            cleaned_res_list = clean_acc_res(res_list, allowed_results, cleaned_res_list)\n",
    "\n",
    "        # Task: Multiple Choice\n",
    "        elif \"mc\" in desc:\n",
    "            allowed_results = [\"A\", \"B\", \"C\", \"D\"]  # Allowed answers for multiple choice\n",
    "            cleaned_res_list = clean_mc_res(res_list, allowed_results, cleaned_res_list)\n",
    "\n",
    "        # Task: Cloze Test\n",
    "        elif \"cloze\" in desc:\n",
    "            print(\"Dataset shape before processing:\", df_curr.shape)\n",
    "            allowed_results = [\"so\", \"because\", \"then\", \"after\"]  # Expected words in cloze test\n",
    "            cleaned_res_list = clean_cloze_res(res_list, allowed_results, cleaned_res_list)\n",
    "\n",
    "        # Store cleaned answers in a new column\n",
    "        df_curr[\"answer_greedy_cleaned\"] = cleaned_res_list\n",
    "\n",
    "        # Define output file path: Replace original file extension with \"_cleaned.tsv\"\n",
    "        if \".csv\" in path:\n",
    "            out_path = path.replace(\".csv\", \"_cleaned.tsv\")\n",
    "        elif \".tsv\" in path:\n",
    "            out_path = path.replace(\".tsv\", \"_cleaned.tsv\")\n",
    "\n",
    "        # Save the cleaned dataset as a tab-separated file\n",
    "        df_curr.to_csv(out_path, index=False, sep=\"\\t\")\n",
    "\n",
    "        print(f\"Cleaned results saved to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc32052",
   "metadata": {},
   "source": [
    "## Multiple choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759c7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_few_dict = {\n",
    "       \"gpt4omini\": \"./data/res/mc/fewshot/raw/mult_choice_res_outlines_gpt-4o-mini_few.tsv\",\n",
    "    \"gpt4o\": \"./data/res/mc/fewshot/raw/mult_choice_res_outlines_gpt-4o_few.tsv\",\n",
    "    \"falcon\": \"./data/res/mc/fewshot/raw/res_multiple_choice-falcon-7b-instruct-connective.csv\",\n",
    "    \"gemma\": \"./data/res/mc/fewshot/raw/res_multiple_choice-gemma-2-9b-it-connective.csv\",\n",
    "    \"llama\": \"./data/res/mc/fewshot/raw/res_multiple_choice-Meta-Llama-3.1-8B-Instruct-connective.csv\",\n",
    "    \"mistral\": \"./data/res/mc/fewshot/raw/res_multiple_choice-Mistral-7B-Instruct-v0.3-connective.csv\",\n",
    "    \"qwen\": \"./data/res/mc/fewshot/raw/res_multiple_choice-Qwen2.5-7B-Instruct-connective.csv\"\n",
    "}\n",
    "\n",
    "clean_results(\"mc_few\", mc_few_dict)\n",
    "\n",
    "###########*******\n",
    "\n",
    "\n",
    "mc_zero_dict = {\n",
    "    \"gpt4omini\": \"./data/res/mc/zeroshot/raw/mult_choice_res_outlines_gpt-4o-mini.tsv\",\n",
    "    \"gpt4o\": \"./data/res/mc/zeroshot/raw/mult_choice_res_outlines_gpt-4o.tsv\",\n",
    "    \"falcon\": \"./data/res/mc/zeroshot/raw/res_multiple_choice-falcon-7b-instruct-connective.csv\",\n",
    "    \"gemma\": \"./data/res/mc/zeroshot/raw/res_multiple_choice-gemma-2-9b-it-connective.csv\",\n",
    "    \"llama\": \"./data/res/mc/zeroshot/raw/res_multiple_choice-Meta-Llama-3.1-8B-Instruct-connective.csv\",\n",
    "    \"mistral\": \"./data/res/mc/zeroshot/raw/res_multiple_choice-Mistral-7B-Instruct-v0.3-connective.csv\",\n",
    "    \"qwen\": \"./data/res/mc/zeroshot/raw/res_multiple_choice-Qwen2.5-7B-Instruct-connective.csv\"\n",
    "}\n",
    "\n",
    "\n",
    "clean_results(\"mc_zero\", mc_zero_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589521f3",
   "metadata": {},
   "source": [
    "## Acceptability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba3116",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = dict()\n",
    "\n",
    "\n",
    "acc_few_dict = {\"falcon\" : \"./data/res/acceptability/fewshot/raw/accept_res_outlines_falcon-7b-instruct.tsv\",\n",
    "\"gemma\" : \"./data/res/acceptability/fewshot/raw/accept_res_outlines_gemma-2-9b-it.tsv\",\n",
    "\"gpt4omini\" : \"./data/res/acceptability/fewshot/raw/accept_res_outlines_gpt-4o-mini_few.tsv\",\n",
    "\"gpt4o\" : \"./data/res/acceptability/fewshot/raw/accept_res_outlines_gpt-4o_few.tsv\",\n",
    "\"llama\" : \"./data/res/acceptability/fewshot/raw/accept_res_outlines_Meta-Llama-3.1-8B-Instruct.tsv\",\n",
    "\"mistral\" : \"./data/res/acceptability/fewshot/raw/accept_res_outlines_Mistral-7B-Instruct-v0.3.tsv\",\n",
    "\"qwen\" : \"./data/res/acceptability/fewshot/raw/accept_res_outlines_Qwen2.5-7B-Instruct.tsv\" }\n",
    "\n",
    "clean_results(\"acc_few\", acc_few_dict)\n",
    "\n",
    "###########*******\n",
    "\n",
    "acc_zero_dict = {\"falcon\" : \"./data/res/acceptability/zeroshot/raw/accept_res_outlines_falcon-7b-instruct.tsv\",\n",
    "\"gemma\" : \"./data/res/acceptability/zeroshot/raw/accept_res_outlines_gemma-2-9b-it.tsv\",\n",
    "\"gpt4omini\" : \"./data/res/acceptability/zeroshot/raw/accept_res_outlines_gpt-4o-mini_zero.tsv\",\n",
    "\"gpt4o\" : \"./data/res/acceptability/zeroshot/raw/accept_res_outlines_gpt-4o_zero.tsv\",\n",
    "\"llama\" : \"./data/res/acceptability/zeroshot/raw/accept_res_outlines_Meta-Llama-3.1-8B-Instruct.tsv\",\n",
    "\"mistral\" : \"./data/res/acceptability/zeroshot/raw/accept_res_outlines_Mistral-7B-Instruct-v0.3.tsv\",\n",
    "\"qwen\" : \"./data/res/acceptability/zeroshot/raw/accept_res_outlines_Qwen2.5-7B-Instruct.tsv\" }\n",
    "\n",
    "clean_results(\"acc_zero\", acc_zero_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "acc_qwen = {\"qwen05\" : \"./data/res/acceptability/fewshot/raw/accept_res_outlines_Qwen2.5-0.5B-Instruct.tsv\",\n",
    "\"qwen5\" : \"./data/res/acceptability/fewshot/raw/accept_res_outlines_Qwen2.5-1.5B-Instruct.tsv\",\n",
    "\"qwen3\" : \"./data/res/acceptability/fewshot/raw/accept_res_outlines_Qwen2.5-3B-Instruct.tsv\",\n",
    "\"qwen14\": \"./data/res/acceptability/fewshot/raw/accept_few_Qwen2.5-14B-Instruct.tsv\",\n",
    "\"qwen32\": \"./data/res/acceptability/fewshot/raw/accept_few_Qwen2.5-32B-Instruct.tsv\"}\n",
    "\n",
    "clean_results(\"acc_qwen\", acc_qwen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd7c01c",
   "metadata": {},
   "source": [
    "## Cloze-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f14c7061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Processing Task: cloze_few\n",
      "Processing model: falcon\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/fewshot/raw/cloze_res_outlines_falcon-7b-instruct_cleaned.tsv\n",
      "Processing model: gemma\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/fewshot/raw/cloze_res_outlines_gemma-2-9b-it_cleaned.tsv\n",
      "Processing model: gpt4omini\n",
      "Dataset shape: (1200, 10)\n",
      "Dataset shape before processing: (1200, 10)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/fewshot/raw/cloze_res_outlines_gpt-4o-mini_few_cleaned.tsv\n",
      "Processing model: llama\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/fewshot/raw/cloze_res_outlines_Meta-Llama-3.1-8B-Instruct_cleaned.tsv\n",
      "Processing model: mistral\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/fewshot/raw/cloze_res_outlines_Mistral-7B-Instruct-v0.3_cleaned.tsv\n",
      "Processing model: qwen\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Error: Multiple different conjunctions detected: {'because', 'after'}. Case: Conflicting conjunctions in response because after because\n",
      "Error: Multiple different conjunctions detected: {'so', 'then'}. Case: Conflicting conjunctions in response so then because\n",
      "Error: Multiple different conjunctions detected: {'because', 'after'}. Case: Conflicting conjunctions in response because after because\n",
      "Error: Multiple different conjunctions detected: {'because', 'after'}. Case: Conflicting conjunctions in response because after because\n",
      "Error: Multiple different conjunctions detected: {'because', 'then'}. Case: Conflicting conjunctions in response because then because\n",
      "Error: Multiple different conjunctions detected: {'because', 'after'}. Case: Conflicting conjunctions in response because after because\n",
      "Error: Multiple different conjunctions detected: {'because', 'then'}. Case: Conflicting conjunctions in response because then because\n",
      "Error: Multiple different conjunctions detected: {'because', 'then'}. Case: Conflicting conjunctions in response because then because\n",
      "Error: Multiple different conjunctions detected: {'because', 'after'}. Case: Conflicting conjunctions in response because after because\n",
      "Error: Multiple different conjunctions detected: {'because', 'then'}. Case: Conflicting conjunctions in response because then after\n",
      "Error: Multiple different conjunctions detected: {'because', 'after'}. Case: Conflicting conjunctions in response because after because\n",
      "Error: Multiple different conjunctions detected: {'because', 'then'}. Case: Conflicting conjunctions in response because then after\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/fewshot/raw/cloze_res_outlines_Qwen2.5-7B-Instruct_cleaned.tsv\n",
      "Processing model: gpt4o\n",
      "Dataset shape: (1200, 10)\n",
      "Dataset shape before processing: (1200, 10)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/fewshot/raw/cloze_res_outlines_gpt-4o_few_cleaned.tsv\n",
      "**** Processing Task: cloze_zero\n",
      "Processing model: falcon\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/zeroshot/raw/cloze_res_outlines_falcon-7b-instruct_cleaned.tsv\n",
      "Processing model: gemma\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/zeroshot/raw/cloze_res_outlines_gemma-2-9b-it_cleaned.tsv\n",
      "Processing model: gpt4omini\n",
      "Dataset shape: (1200, 10)\n",
      "Dataset shape before processing: (1200, 10)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/zeroshot/raw/cloze_res_outlines_gpt-4o-mini_zero_cleaned.tsv\n",
      "Processing model: gpt4o\n",
      "Dataset shape: (1200, 10)\n",
      "Dataset shape before processing: (1200, 10)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/zeroshot/raw/cloze_res_outlines_gpt-4o_zero_cleaned.tsv\n",
      "Processing model: llama\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Error: Multiple different conjunctions detected: {'because', 'then'}. Case: Conflicting conjunctions in response # then\n",
      "because the\n",
      "Error: Multiple different conjunctions detected: {'because', 'then'}. Case: Conflicting conjunctions in response # then\n",
      "because diana\n",
      "Error: Multiple different conjunctions detected: {'so', 'because'}. Case: Conflicting conjunctions in response so\n",
      "because\n",
      "after\n",
      "Error: Multiple different conjunctions detected: {'because', 'then'}. Case: Conflicting conjunctions in response # then\n",
      "because the\n",
      "Error: Multiple different conjunctions detected: {'so', 'because'}. Case: Conflicting conjunctions in response so\n",
      "because\n",
      "after\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/zeroshot/raw/cloze_res_outlines_Meta-Llama-3.1-8B-Instruct_cleaned.tsv\n",
      "Processing model: mistral\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/zeroshot/raw/cloze_res_outlines_Mistral-7B-Instruct-v0.3_cleaned.tsv\n",
      "Processing model: qwen\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ./data/res/cloze/zeroshot/raw/cloze_res_outlines_Qwen2.5-7B-Instruct_cleaned.tsv\n"
     ]
    }
   ],
   "source": [
    "###########*******\n",
    "\n",
    "\n",
    "cloze_few_dict = {\n",
    "    \"falcon\": \"./data/res/cloze/fewshot/raw/cloze_res_outlines_falcon-7b-instruct.tsv\",\n",
    "    \"gemma\": \"./data/res/cloze/fewshot/raw/cloze_res_outlines_gemma-2-9b-it.tsv\",\n",
    "    \"gpt4omini\": \"./data/res/cloze/fewshot/raw/cloze_res_outlines_gpt-4o-mini_few.tsv\",\n",
    "    \"llama\": \"./data/res/cloze/fewshot/raw/cloze_res_outlines_Meta-Llama-3.1-8B-Instruct.tsv\",\n",
    "    \"mistral\": \"./data/res/cloze/fewshot/raw/cloze_res_outlines_Mistral-7B-Instruct-v0.3.tsv\",\n",
    "    \"qwen\": \"./data/res/cloze/fewshot/raw/cloze_res_outlines_Qwen2.5-7B-Instruct.tsv\",\n",
    "    \"gpt4o\": \"./data/res/cloze/fewshot/raw/cloze_res_outlines_gpt-4o_few.tsv\",\n",
    "}\n",
    "\n",
    "\n",
    "clean_results(\"cloze_few\", cloze_few_dict)\n",
    "#print(len(cleaned_res_list))\n",
    "\n",
    "###########*******\n",
    "\n",
    "\n",
    "cloze_zero_dict = {\n",
    "    \"falcon\": \"./data/res/cloze/zeroshot/raw/cloze_res_outlines_falcon-7b-instruct.tsv\",\n",
    "    \"gemma\": \"./data/res/cloze/zeroshot/raw/cloze_res_outlines_gemma-2-9b-it.tsv\",\n",
    "    \"gpt4omini\": \"./data/res/cloze/zeroshot/raw/cloze_res_outlines_gpt-4o-mini_zero.tsv\",\n",
    "    \"gpt4o\": \"./data/res/cloze/zeroshot/raw/cloze_res_outlines_gpt-4o_zero.tsv\",\n",
    "    \"llama\": \"./data/res/cloze/zeroshot/raw/cloze_res_outlines_Meta-Llama-3.1-8B-Instruct.tsv\",\n",
    "    \"mistral\": \"./data/res/cloze/zeroshot/raw/cloze_res_outlines_Mistral-7B-Instruct-v0.3.tsv\",\n",
    "    \"qwen\": \"./data/res/cloze/zeroshot/raw/cloze_res_outlines_Qwen2.5-7B-Instruct.tsv\"\n",
    "}\n",
    "\n",
    "\n",
    "clean_results(\"cloze_zero\", cloze_zero_dict)\n",
    "#print(len(cleaned_res_list))\n",
    "\n",
    "\n",
    "###########*******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e11fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a7d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask",
   "language": "python",
   "name": "mask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
