{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2eb856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227a071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_acc_res(res_list, allowed_results, cleaned_res_list):\n",
    "    \"\"\"\n",
    "    Cleans and extracts numerical acceptability ratings from a list of responses.\n",
    "\n",
    "    This function processes responses from a language model and extracts numerical values \n",
    "    that represent acceptability ratings. It ensures valid formatting and handles edge cases \n",
    "    where multiple numbers or unexpected patterns appear.\n",
    "\n",
    "    Parameters:\n",
    "    - res_list (list): List of raw acceptability rating responses.\n",
    "    - allowed_results (set or list): A collection of valid acceptability ratings.\n",
    "    - cleaned_res_list (list): A list where cleaned results will be stored.\n",
    "\n",
    "    Returns:\n",
    "    - list: The updated cleaned_res_list with extracted ratings or a placeholder (-1) if the rating is invalid.\n",
    "    \"\"\"\n",
    "    for response in res_list:\n",
    "        if re.findall(r'[0-9]+\\s', response):\n",
    "            # Extract numbers followed by a space and remove whitespace\n",
    "            extracted_numbers = [x.strip() for x in re.findall(r'[0-9]+\\s', response)]\n",
    "            \n",
    "            if len(extracted_numbers) == 2:\n",
    "                # Handling cases where two numbers appear, such as \"n out of 10\" or \"after 10 years\"\n",
    "                if extracted_numbers[1] != \"10\":\n",
    "                    # If numbers are different, check if it refers to a known case (e.g., \"5 minutes\")\n",
    "                    if extracted_numbers[0] != extracted_numbers[1]:\n",
    "                        if extracted_numbers[1] == \"5\":\n",
    "                            cleaned_result = extracted_numbers[0]  # Refers to \"5 minutes\"\n",
    "                        else:\n",
    "                            print(\"Warning: Unhandled case – two different numbers detected.\", \n",
    "                                  \"Case: Two numbers found in response:\", extracted_numbers)\n",
    "                            break\n",
    "                    else:\n",
    "                        cleaned_result = extracted_numbers[0]\n",
    "                else:\n",
    "                    cleaned_result = extracted_numbers[0]\n",
    "            elif len(extracted_numbers) > 2:\n",
    "                print(\"Error: More than two numerical values found in response.\", \"Case: Multiple numbers detected:\", response)\n",
    "                break\n",
    "            else:\n",
    "                cleaned_result = extracted_numbers[0]\n",
    "        \n",
    "        elif re.findall(r'[0-9]+$', response):\n",
    "            # Extract numbers at the end of the response\n",
    "            extracted_numbers = re.findall(r'[0-9]+$', response)\n",
    "            if len(extracted_numbers) > 1:\n",
    "                print(\"Error: Multiple ratings detected at the end of the response.\", \"Case: Multiple final numbers:\", response)\n",
    "                break\n",
    "            cleaned_result = extracted_numbers[0].strip()\n",
    "\n",
    "        elif re.findall(r'[0-9]+\\<\\|endoftext\\|\\>', response):\n",
    "            # Extract numbers followed by the end-of-text token\n",
    "            extracted_numbers = re.findall(r'[0-9]+\\<\\|endoftext\\|\\>', response)\n",
    "            if len(extracted_numbers) > 1:\n",
    "                print(\"Error: Multiple ratings detected before the end-of-text token.\", \"Case: Multiple occurrences with <|endoftext|>:\", response)\n",
    "                break\n",
    "            cleaned_result = extracted_numbers[0].replace('<|endoftext|>', '').strip()\n",
    "\n",
    "        elif re.findall(r'\\d+ out of 10', response):\n",
    "            # Extract ratings in the format \"X out of 10\"\n",
    "            extracted_numbers = re.findall(r'\\d+ out of 10', response)\n",
    "            if len(extracted_numbers) > 1:\n",
    "                print(\"Error: Multiple 'X out of 10' ratings detected.\", \"Case: Multiple 'out of 10' responses:\", response)\n",
    "                break\n",
    "            cleaned_result = extracted_numbers[0].replace(\"out of 10\", \"\").strip()\n",
    "\n",
    "        elif re.findall(r'Rating: \\d+', response):\n",
    "            # Extract numerical ratings in the format \"Rating: X\"\n",
    "            extracted_numbers = re.findall(r'Rating: \\d+', response)\n",
    "            if len(extracted_numbers) > 1:\n",
    "                print(\"Error: Multiple ratings detected in 'Rating: X' format.\", \"Case: Multiple 'Rating:' responses:\", response)\n",
    "                break\n",
    "            cleaned_result = extracted_numbers[0].replace(\"Rating: \", \"\").strip()\n",
    "\n",
    "        elif re.findall(r'[0-9]+\\.', response):\n",
    "            # Extract numbers followed by a period (potentially a numbered list)\n",
    "            extracted_numbers = [x.strip() for x in re.findall(r'[0-9]+\\.', response)]\n",
    "            \n",
    "            if len(extracted_numbers) == 2:\n",
    "                # Handling cases where two numbers appear, possibly indicating a list\n",
    "                if extracted_numbers[1] != \"10\":\n",
    "                    if extracted_numbers[0] != extracted_numbers[1]:\n",
    "                        if extracted_numbers[0] == \"1.\" and extracted_numbers[1] == \"2.\":\n",
    "                            cleaned_result = response  # Retain original response for sequential list items\n",
    "                        else:\n",
    "                            if extracted_numbers[1] == \"5\":\n",
    "                                cleaned_result = extracted_numbers[0].replace(\".\", \"\").strip()\n",
    "                            else:\n",
    "                                print(\"Warning: Unhandled case – two different numbers found in period format.\", \n",
    "                                      \"Case: Numbered list mismatch:\", extracted_numbers)\n",
    "                                break\n",
    "                    else:\n",
    "                        cleaned_result = extracted_numbers[0].replace(\".\", \"\").strip()\n",
    "                else:\n",
    "                    cleaned_result = extracted_numbers[0].replace(\".\", \"\").strip()\n",
    "            elif len(extracted_numbers) > 2:\n",
    "                print(\"Error: More than two numerical values found in period format.\", \"Case: Multiple list-like numbers:\", response)\n",
    "                break\n",
    "            elif len(extracted_numbers) == 1:\n",
    "                cleaned_result = extracted_numbers[0].replace(\".\", \"\").strip()\n",
    "        \n",
    "        else:\n",
    "            cleaned_result = response.strip()\n",
    "\n",
    "        # Validate the cleaned result against allowed acceptability ratings\n",
    "        if cleaned_result in allowed_results:\n",
    "            cleaned_res_list.append(cleaned_result)\n",
    "        else:\n",
    "            cleaned_res_list.append(\"-1\")  # Placeholder for invalid results\n",
    "\n",
    "    print(f\"Processing complete. Total cleaned acceptability ratings: {len(cleaned_res_list)}\")\n",
    "    return cleaned_res_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abfddc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_cloze_res(res_list, allowed_results, cleaned_res_list):\n",
    "    \"\"\"\n",
    "    Cleans and standardizes responses for a cloze test task.\n",
    "\n",
    "    This function processes responses from a language model, extracts relevant words, \n",
    "    removes unnecessary tokens, and validates the responses against a predefined set of \n",
    "    allowed results.\n",
    "\n",
    "    Parameters:\n",
    "    - res_list (list): List of raw responses from an LLM.\n",
    "    - allowed_results (set or list): A collection of acceptable words for the cloze test.\n",
    "    - cleaned_res_list (list): A list where cleaned responses will be stored.\n",
    "\n",
    "    Returns:\n",
    "    - list: The updated cleaned_res_list with extracted responses or 'error' if the response is invalid.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Total responses received: {len(res_list)}\")\n",
    "\n",
    "    for response in res_list:\n",
    "        response = response.lower().strip()\n",
    "\n",
    "        # If the response doesn't contain any allowed words, mark it as an error\n",
    "        if not any(word in response for word in allowed_results):\n",
    "            cleaned_result = \"error\"\n",
    "        else:\n",
    "            # Standardize the response by removing unnecessary words and symbols\n",
    "            response = response.replace('\"', '').replace(\"'\", \"\").replace(\"explanation\", \" \").replace(\"sentence\", \" \")\\\n",
    "                .replace(\"explanation:\", \" \").replace(\"reason\", \" \").replace(\"reasoning\", \" \").replace(\"note\", \" \")\\\n",
    "                .replace(\"answer\", \" \").replace(\"template\", \" \").replace(\"event\", \" \").replace(\".\", \"\")\\\n",
    "                .replace(\"[\", \"\").replace(\"]\", \"\").replace(\":\", \"\").replace(\"ing\", \"\").replace(\"<|endoftext|>\", \"\")\\\n",
    "                .replace(\"<end_of_turn><eos>\", \"\").replace(\"<end_of_turn>\", \"\")\\\n",
    "                .replace(\"</s>\", \"\").replace(\"*\", \"\").strip()\n",
    "\n",
    "            # Check if the response contains conjunctions like \"so,\" \"because,\" \"then,\" or \"after\"\n",
    "            if re.findall(r'(so|because|then|after)\\s', response):\n",
    "                extracted_words = re.findall(r'(so|because|then|after)\\s', response)\n",
    "\n",
    "                if len(set(extracted_words)) == 1:\n",
    "                    if extracted_words[0] in allowed_results:\n",
    "                        cleaned_result = extracted_words[0].strip()\n",
    "                    else:\n",
    "                        print(f\"Warning: Extracted word '{extracted_words[0]}' is not in allowed results.\", \"Case: Single conjunction found in sentence\", response)\n",
    "                        cleaned_result = \"error\"\n",
    "                else:\n",
    "                    print(f\"Error: Multiple different conjunctions detected: {set(extracted_words)}.\", \"Case: Conflicting conjunctions in response\", response)\n",
    "                    cleaned_result = \"error\"\n",
    "\n",
    "            elif re.findall(r'(so|because|then|after)$', response):\n",
    "                extracted_words = re.findall(r'(so|because|then|after)$', response)\n",
    "\n",
    "                if len(set(extracted_words)) == 1:\n",
    "                    if extracted_words[0] in allowed_results:\n",
    "                        cleaned_result = extracted_words[0].strip()\n",
    "                    else:\n",
    "                        print(f\"Warning: Extracted word '{extracted_words[0]}' at sentence end is not in allowed results.\", \"Case: Conjunction at the end of response\", response)\n",
    "                        cleaned_result = \"error\"\n",
    "                else:\n",
    "                    # The model returns more than one connective. This is an error. Uncomment to check\n",
    "                    #print(f\"Error: Multiple different conjunctions detected at the end: {set(extracted_words)}.\", \"Case: Conflicting conjunctions at sentence end\", response)\n",
    "                    cleaned_result = \"error\"\n",
    "\n",
    "            else:\n",
    "                # Further cleaning by removing unwanted characters\n",
    "                cleaned_string = response.replace('\"', '').replace(\"'\", \"\").replace(\"\\n-\", \"\").replace(\"*\", \"\").strip()\n",
    "\n",
    "                # Check if the cleaned response is allowed\n",
    "                if cleaned_string not in allowed_results:\n",
    "                    word_list = cleaned_string.split()\n",
    "\n",
    "                    # If all words in the response are the same, keep only one\n",
    "                    if len(set(word_list)) == 1 and word_list[0] in allowed_results:\n",
    "                        cleaned_result = word_list[0].strip()\n",
    "                    else:\n",
    "                        # The model returns more than one connective. This is an error. Uncomment to check\n",
    "                        #print(f\"Error: Invalid response '{cleaned_string}' detected.\", \"Case: Response contains multiple unrecognized words\", response)\n",
    "                        cleaned_result = \"error\"\n",
    "                else:\n",
    "                    cleaned_result = cleaned_string\n",
    "\n",
    "        # Append the cleaned result to the list\n",
    "        try:\n",
    "            cleaned_res_list.append(cleaned_result)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception encountered while appending result: {e}\", \"Response causing issue:\", response)\n",
    "\n",
    "    print(f\"Processing complete. Total cleaned cloze test responses: {len(cleaned_res_list)}\")\n",
    "    return cleaned_res_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "065a5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mc_res(res_list, allowed_results, cleaned_res_list):\n",
    "    \"\"\"\n",
    "    Cleans and standardizes multiple-choice responses by extracting valid choices (A, B, C, or D)\n",
    "    while filtering out invalid responses.\n",
    "    \n",
    "    Parameters:\n",
    "    - res_list (list): List of raw responses from an LLM.\n",
    "    - allowed_results (list): A collection of valid multiple-choice answers (e.g., ['A', 'B', 'C', 'D']).\n",
    "    - cleaned_res_list (list): A list where cleaned responses will be stored.\n",
    "\n",
    "    Returns:\n",
    "    - list: The updated cleaned_res_list with extracted multiple-choice answers or 'error' for invalid responses.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Initial number of responses: {len(res_list)}\")\n",
    "\n",
    "    # Loop through each response in the list\n",
    "    for r in res_list:\n",
    "        r = r.strip()  # Remove leading and trailing whitespace\n",
    "        \n",
    "        # Check if the response contains any valid answer (A, B, C, or D)\n",
    "        if not any(x in r for x in allowed_results):\n",
    "            cleaned_result = \"error\"  # If no valid answer found, mark as error\n",
    "        else:\n",
    "            # If the response is exactly one of the allowed results, keep it\n",
    "            if r in allowed_results:\n",
    "                cleaned_result = r\n",
    "            elif r == \"Answer\\n\" or re.findall(r'Answer:?$', r) or \"_______________________  (Choose\" in r:\n",
    "                # Exclude certain invalid responses\n",
    "                cleaned_result = \"error\"\n",
    "            else:\n",
    "                # Check different formats in which the answer might appear\n",
    "                if re.findall(r'(A|B|C|D) *\\n', r):\n",
    "                    regex_list = [x.strip() for x in re.findall(r'(A|B|C|D) *\\n', r)]\n",
    "                    if len(set(regex_list)) == 1 and regex_list[0] in allowed_results:\n",
    "                        cleaned_result = regex_list[0]\n",
    "                    else:\n",
    "                        print(f\"Ambiguous or invalid answer format (newline-separated): {r}\")\n",
    "                        cleaned_result = \"error\"\n",
    "\n",
    "                elif re.findall(r'\\*+(A|B|C|D)\\*+', r):\n",
    "                    regex_list = [x.replace(\"*\", \"\").strip() for x in re.findall(r'\\*+(A|B|C|D)\\*+', r)]\n",
    "                    if len(set(regex_list)) == 1 and regex_list[0] in allowed_results:\n",
    "                        cleaned_result = regex_list[0]\n",
    "                    else:\n",
    "                        print(f\"Ambiguous or invalid answer format (asterisks): {r}\")\n",
    "                        cleaned_result = \"error\"\n",
    "\n",
    "                elif re.findall(r'(A|B|C|D)</s>', r):\n",
    "                    regex_list = [x.replace(\"</s>\", \"\").strip() for x in re.findall(r'(A|B|C|D)</s>', r)]\n",
    "                    if len(set(regex_list)) == 1 and regex_list[0] in allowed_results:\n",
    "                        cleaned_result = regex_list[0]\n",
    "                    else:\n",
    "                        print(f\"Ambiguous or invalid answer format (slash-terminated): {r}\")\n",
    "                        cleaned_result = \"error\"\n",
    "\n",
    "                elif re.findall(r'Answer: (A|B|C|D)', r):\n",
    "                    regex_list = [x.replace(\"Answer: \", \"\").strip() for x in re.findall(r'Answer: (A|B|C|D)', r)]\n",
    "                    if len(set(regex_list)) == 1 and regex_list[0] in allowed_results:\n",
    "                        cleaned_result = regex_list[0]\n",
    "                    else:\n",
    "                        print(f\"Ambiguous or invalid answer format (Answer: X): {r}\")\n",
    "                        cleaned_result = \"error\"\n",
    "\n",
    "                elif re.findall(r'\"(A|B|C|D)\"', r):\n",
    "                    regex_list = [x.replace('\"', '').strip() for x in re.findall(r'\"(A|B|C|D)\"', r)]\n",
    "                    if len(set(regex_list)) == 1 and regex_list[0] in allowed_results:\n",
    "                        cleaned_result = regex_list[0]\n",
    "                    else:\n",
    "                        print(f\"Ambiguous or invalid answer format (quoted): {r}\")\n",
    "                        cleaned_result = \"error\"\n",
    "\n",
    "                elif re.findall(r'(A|B|C|D)\\.', r):\n",
    "                    regex_list = [x.replace('.', '').strip() for x in re.findall(r'(A|B|C|D)\\.', r)]\n",
    "                    if len(set(regex_list)) == 1 and regex_list[0] in allowed_results:\n",
    "                        cleaned_result = regex_list[0]\n",
    "                    else:\n",
    "                        #print(f\"Ambiguous or invalid answer format (dot-separated): {r}\")\n",
    "                        cleaned_result = \"error\"\n",
    "\n",
    "                elif re.findall(r'\\((A|B|C|D)\\)', r):\n",
    "                    regex_list = [x.replace('(', '').replace(')', '').strip() for x in re.findall(r'\\((A|B|C|D)\\)', r)]\n",
    "                    if len(set(regex_list)) == 1 and regex_list[0] in allowed_results:\n",
    "                        cleaned_result = regex_list[0]\n",
    "                    else:\n",
    "                        print(f\"Ambiguous or invalid answer format (parentheses): {r}\")\n",
    "                        cleaned_result = \"error\"\n",
    "\n",
    "                elif re.findall(r'\\[(A|B|C|D)\\]', r):\n",
    "                    regex_list = [x.replace('[', '').replace(']', '').strip() for x in re.findall(r'\\[(A|B|C|D)\\]', r)]\n",
    "                    if len(set(regex_list)) == 1 and regex_list[0] in allowed_results:\n",
    "                        cleaned_result = regex_list[0]\n",
    "                    else:\n",
    "                        print(f\"Ambiguous or invalid answer format (brackets): {r}\")\n",
    "                        cleaned_result = \"error\"\n",
    "\n",
    "                elif re.findall(r'(A|B|C|D) \\(', r):\n",
    "                    regex_list = [x.replace(' (', '').strip() for x in re.findall(r'(A|B|C|D) \\(', r)]\n",
    "                    if len(set(regex_list)) == 1 and regex_list[0] in allowed_results:\n",
    "                        cleaned_result = regex_list[0]\n",
    "                    else:\n",
    "                        print(f\"Ambiguous or invalid answer format (before parentheses): {r}\")\n",
    "                        cleaned_result = \"error\"\n",
    "\n",
    "                elif re.findall(r'\\[Insert (the )?(word|answer) (A|B|C|D)( here)?', r):\n",
    "                    regex_list = [x.replace('\\[Insert word ', '').replace('\\[Insert answer ', '').replace(\" here\", \"\").replace('\\[Insert the word ', '').strip() for x in re.findall(r'\\[Insert word (A|B|C|D) here', r)]\n",
    "                    if len(set(regex_list)) == 1 and regex_list[0] in allowed_results:\n",
    "                        cleaned_result = regex_list[0]\n",
    "                    else:\n",
    "                        print(f\"Ambiguous or invalid answer format (insert statement): {r}\")\n",
    "                        cleaned_result = \"error\"\n",
    "\n",
    "                elif re.findall(r'```(A|B|C|D)```', r):\n",
    "                    regex_list = [x.replace('```', '').strip() for x in re.findall(r'```(A|B|C|D)```', r)]\n",
    "                    if len(set(regex_list)) == 1 and regex_list[0] in allowed_results:\n",
    "                        cleaned_result = regex_list[0]\n",
    "                    else:\n",
    "                        print(f\"Ambiguous or invalid answer format (markdown code block): {r}\")\n",
    "                        cleaned_result = \"error\"\n",
    "\n",
    "                else:\n",
    "                    cleaned_result = \"error\"  # If no valid format found, mark as error\n",
    "\n",
    "        # Append the cleaned result if it is valid\n",
    "        if cleaned_result == \"error\":\n",
    "            #print(f\"Invalid response detected: {r}\")\n",
    "            pass\n",
    "        else:\n",
    "            if cleaned_result not in allowed_results:\n",
    "                print(f\"Unexpected cleaned result (not in allowed results): {r}\")\n",
    "\n",
    "        try:\n",
    "            cleaned_res_list.append(cleaned_result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error while appending result: {r} | Exception: {e}\")\n",
    "\n",
    "    # Print final statistics\n",
    "    print(f\"Final number of cleaned responses: {len(cleaned_res_list)}\")\n",
    "    print(f\"Response distribution: {Counter(cleaned_res_list)}\")\n",
    "\n",
    "    return cleaned_res_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be41bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_results(desc, _dict):\n",
    "    \"\"\"\n",
    "    Cleans and standardizes generated answers for different NLP tasks \n",
    "    (acceptability rating, multiple choice, and cloze test).\n",
    "    \n",
    "    Parameters:\n",
    "    - desc (str): Description of the task type (e.g., \"acc\", \"mc\", \"cloze\").\n",
    "    - _dict (dict): Dictionary where keys are model names and values are file paths \n",
    "                    to datasets containing generated answers.\n",
    "\n",
    "    The function reads results from CSV/TSV files, processes answers based on \n",
    "    the task type, and saves a cleaned version of the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"**** Processing Task:\", desc)\n",
    "\n",
    "    # Iterate through each model and its corresponding dataset path\n",
    "    for model, path in _dict.items():\n",
    "        print(\"Processing model:\", model)\n",
    "        \n",
    "        # Read the dataset (expects tab-separated values)\n",
    "        df_curr = pd.read_csv(path, sep=\"\\t\")\n",
    "        print(\"Dataset shape:\", df_curr.shape)  # Print dataset dimensions (rows, columns)\n",
    "        \n",
    "        # Dictionary key to store accuracy results\n",
    "        key = desc + \"_\" + model\n",
    "\n",
    "        # Extract generated answers: The column name may vary between different datasets\n",
    "        if \"generated_answer_greedy\" in df_curr:\n",
    "            res_list = df_curr['generated_answer_greedy'].tolist()\n",
    "        elif \"generated_answer_normal\" in df_curr:\n",
    "            res_list = df_curr['generated_answer_normal'].tolist()\n",
    "        else:\n",
    "            print(\"Error: No recognized answer column found. Available columns:\", df_curr.columns)\n",
    "            continue  # Skip to the next dataset if no valid column is found\n",
    "\n",
    "        cleaned_res_list = []  # Initialize an empty list to store cleaned responses\n",
    "\n",
    "        # Task: Acceptability Rating\n",
    "        if \"acc\" in desc:\n",
    "            allowed_results = [str(x) for x in range(1, 11)]  # Allowed ratings: 1 to 10\n",
    "            cleaned_res_list = clean_acc_res(res_list, allowed_results, cleaned_res_list)\n",
    "\n",
    "        # Task: Multiple Choice\n",
    "        elif \"mc\" in desc:\n",
    "            allowed_results = [\"A\", \"B\", \"C\", \"D\"]  # Allowed answers for multiple choice\n",
    "            cleaned_res_list = clean_mc_res(res_list, allowed_results, cleaned_res_list)\n",
    "\n",
    "        # Task: Cloze Test\n",
    "        elif \"cloze\" in desc:\n",
    "            print(\"Dataset shape before processing:\", df_curr.shape)\n",
    "            allowed_results = [\"so\", \"because\", \"then\", \"after\"]  # Expected words in cloze test\n",
    "            cleaned_res_list = clean_cloze_res(res_list, allowed_results, cleaned_res_list)\n",
    "\n",
    "        # Store cleaned answers in a new column\n",
    "        df_curr[\"answer_greedy_cleaned\"] = cleaned_res_list\n",
    "\n",
    "        # Define output file path: Replace original file extension with \"_cleaned.tsv\"\n",
    "        if \".csv\" in path:\n",
    "            out_path = path.replace(\".csv\", \"_cleaned.tsv\")\n",
    "        elif \".tsv\" in path:\n",
    "            out_path = path.replace(\".tsv\", \"_cleaned.tsv\")\n",
    "\n",
    "        # Save the cleaned dataset as a tab-separated file\n",
    "        df_curr.to_csv(out_path, index=False, sep=\"\\t\")\n",
    "\n",
    "        print(f\"Cleaned results saved to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc32052",
   "metadata": {},
   "source": [
    "## Multiple choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "759c7bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Processing Task: mc_few\n",
      "Processing model: gpt4omini\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'error': 4752, 'A': 28, 'B': 8, 'D': 7, 'C': 5})\n",
      "Cleaned results saved to: ../../data/res/mc/fewshot/mult_choice_res_outlines_gpt-4o-mini_few_cleaned.tsv\n",
      "Processing model: gpt4o\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'C': 1206, 'D': 1110, 'B': 976, 'error': 843, 'A': 665})\n",
      "Cleaned results saved to: ../../data/res/mc/fewshot/mult_choice_res_outlines_gpt-4o_few_cleaned.tsv\n",
      "Processing model: falcon\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Ambiguous or invalid answer format (insert statement): [Insert answer A here\n",
      "Ambiguous or invalid answer format (insert statement): [Insert the word A\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'A': 3458, 'error': 1020, 'D': 162, 'B': 160})\n",
      "Cleaned results saved to: ../../data/res/mc/fewshot/res_multiple_choice-falcon-7b-instruct-connective_cleaned.tsv\n",
      "Processing model: gemma\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'error': 4800})\n",
      "Cleaned results saved to: ../../data/res/mc/fewshot/res_multiple_choice-gemma-2-9b-it-connective_cleaned.tsv\n",
      "Processing model: llama\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'error': 4800})\n",
      "Cleaned results saved to: ../../data/res/mc/fewshot/res_multiple_choice-Meta-Llama-3.1-8B-Instruct-connective_cleaned.tsv\n",
      "Processing model: mistral\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'A': 1341, 'B': 1321, 'C': 1239, 'D': 629, 'error': 270})\n",
      "Cleaned results saved to: ../../data/res/mc/fewshot/res_multiple_choice-Mistral-7B-Instruct-v0.3-connective_cleaned.tsv\n",
      "Processing model: qwen\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'A': 1504, 'B': 1107, 'C': 772, 'error': 758, 'D': 659})\n",
      "Cleaned results saved to: ../../data/res/mc/fewshot/res_multiple_choice-Qwen2.5-7B-Instruct-connective_cleaned.tsv\n",
      "**** Processing Task: mc_zero\n",
      "Processing model: gpt4omini\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'error': 4752, 'A': 29, 'D': 9, 'C': 5, 'B': 5})\n",
      "Cleaned results saved to: ../../data/res/mc/zeroshot/mult_choice_res_outlines_gpt-4o-mini_cleaned.tsv\n",
      "Processing model: gpt4o\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'C': 1336, 'D': 1074, 'B': 927, 'A': 775, 'error': 688})\n",
      "Cleaned results saved to: ../../data/res/mc/zeroshot/mult_choice_res_outlines_gpt-4o_cleaned.tsv\n",
      "Processing model: falcon\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'error': 4785, 'D': 8, 'B': 3, 'C': 2, 'A': 2})\n",
      "Cleaned results saved to: ../../data/res/mc/zeroshot/res_multiple_choice-falcon-7b-instruct-connective_cleaned.tsv\n",
      "Processing model: gemma\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'error': 4800})\n",
      "Cleaned results saved to: ../../data/res/mc/zeroshot/res_multiple_choice-gemma-2-9b-it-connective_cleaned.tsv\n",
      "Processing model: llama\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'error': 4719, 'C': 45, 'A': 21, 'D': 15})\n",
      "Cleaned results saved to: ../../data/res/mc/zeroshot/res_multiple_choice-Meta-Llama-3.1-8B-Instruct-connective_cleaned.tsv\n",
      "Processing model: mistral\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'C': 1764, 'B': 1278, 'D': 1110, 'A': 591, 'error': 57})\n",
      "Cleaned results saved to: ../../data/res/mc/zeroshot/res_multiple_choice-Mistral-7B-Instruct-v0.3-connective_cleaned.tsv\n",
      "Processing model: qwen\n",
      "Dataset shape: (4800, 23)\n",
      "Initial number of responses: 4800\n",
      "Final number of cleaned responses: 4800\n",
      "Response distribution: Counter({'C': 1359, 'A': 1274, 'D': 1005, 'B': 990, 'error': 172})\n",
      "Cleaned results saved to: ../../data/res/mc/zeroshot/res_multiple_choice-Qwen2.5-7B-Instruct-connective_cleaned.tsv\n"
     ]
    }
   ],
   "source": [
    "mc_few_dict = {\n",
    "       \"gpt4omini\": \"../../data/res/mc/fewshot/mult_choice_res_outlines_gpt-4o-mini_few.tsv\",\n",
    "    \"gpt4o\": \"../../data/res/mc/fewshot/mult_choice_res_outlines_gpt-4o_few.tsv\",\n",
    "    \"falcon\": \"../../data/res/mc/fewshot/res_multiple_choice-falcon-7b-instruct-connective.csv\",\n",
    "    \"gemma\": \"../../data/res/mc/fewshot/res_multiple_choice-gemma-2-9b-it-connective.csv\",\n",
    "    \"llama\": \"../../data/res/mc/fewshot/res_multiple_choice-Meta-Llama-3.1-8B-Instruct-connective.csv\",\n",
    "    \"mistral\": \"../../data/res/mc/fewshot/res_multiple_choice-Mistral-7B-Instruct-v0.3-connective.csv\",\n",
    "    \"qwen\": \"../../data/res/mc/fewshot/res_multiple_choice-Qwen2.5-7B-Instruct-connective.csv\"\n",
    "}\n",
    "\n",
    "clean_results(\"mc_few\", mc_few_dict)\n",
    "\n",
    "###########*******\n",
    "\n",
    "\n",
    "mc_zero_dict = {\n",
    "    \"gpt4omini\": \"../../data/res/mc/zeroshot/mult_choice_res_outlines_gpt-4o-mini.tsv\",\n",
    "    \"gpt4o\": \"../../data/res/mc/zeroshot/mult_choice_res_outlines_gpt-4o.tsv\",\n",
    "    \"falcon\": \"../../data/res/mc/zeroshot/res_multiple_choice-falcon-7b-instruct-connective.csv\",\n",
    "    \"gemma\": \"../../data/res/mc/zeroshot/res_multiple_choice-gemma-2-9b-it-connective.csv\",\n",
    "    \"llama\": \"../../data/res/mc/zeroshot/res_multiple_choice-Meta-Llama-3.1-8B-Instruct-connective.csv\",\n",
    "    \"mistral\": \"../../data/res/mc/zeroshot/res_multiple_choice-Mistral-7B-Instruct-v0.3-connective.csv\",\n",
    "    \"qwen\": \"../../data/res/mc/zeroshot/res_multiple_choice-Qwen2.5-7B-Instruct-connective.csv\"\n",
    "}\n",
    "\n",
    "\n",
    "clean_results(\"mc_zero\", mc_zero_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589521f3",
   "metadata": {},
   "source": [
    "## Acceptability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ba3116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Processing Task: acc_few\n",
      "Processing model: falcon\n",
      "Dataset shape: (4800, 26)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/fewshot/accept_res_outlines_falcon-7b-instruct_cleaned.tsv\n",
      "Processing model: gemma\n",
      "Dataset shape: (4800, 26)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/fewshot/accept_res_outlines_gemma-2-9b-it_cleaned.tsv\n",
      "Processing model: gpt4omini\n",
      "Dataset shape: (4800, 25)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/fewshot/accept_res_outlines_gpt-4o-mini_few_cleaned.tsv\n",
      "Processing model: gpt4o\n",
      "Dataset shape: (4800, 25)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/fewshot/accept_res_outlines_gpt-4o_few_cleaned.tsv\n",
      "Processing model: llama\n",
      "Dataset shape: (4800, 26)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/fewshot/accept_res_outlines_Meta-Llama-3.1-8B-Instruct_cleaned.tsv\n",
      "Processing model: mistral\n",
      "Dataset shape: (4800, 26)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/fewshot/accept_res_outlines_Mistral-7B-Instruct-v0.3_cleaned.tsv\n",
      "Processing model: qwen\n",
      "Dataset shape: (4800, 26)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/fewshot/accept_res_outlines_Qwen2.5-7B-Instruct_cleaned.tsv\n",
      "**** Processing Task: acc_zero\n",
      "Processing model: falcon\n",
      "Dataset shape: (4800, 26)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/zeroshot/accept_res_outlines_falcon-7b-instruct_cleaned.tsv\n",
      "Processing model: gemma\n",
      "Dataset shape: (4800, 26)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/zeroshot/accept_res_outlines_gemma-2-9b-it_cleaned.tsv\n",
      "Processing model: gpt4omini\n",
      "Dataset shape: (4800, 25)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/zeroshot/accept_res_outlines_gpt-4o-mini_zero_cleaned.tsv\n",
      "Processing model: gpt4o\n",
      "Dataset shape: (4800, 25)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/zeroshot/accept_res_outlines_gpt-4o_zero_cleaned.tsv\n",
      "Processing model: llama\n",
      "Dataset shape: (4800, 26)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/zeroshot/accept_res_outlines_Meta-Llama-3.1-8B-Instruct_cleaned.tsv\n",
      "Processing model: mistral\n",
      "Dataset shape: (4800, 26)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/zeroshot/accept_res_outlines_Mistral-7B-Instruct-v0.3_cleaned.tsv\n",
      "Processing model: qwen\n",
      "Dataset shape: (4800, 26)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/zeroshot/accept_res_outlines_Qwen2.5-7B-Instruct_cleaned.tsv\n",
      "**** Processing Task: acc_qwen\n",
      "Processing model: qwen05\n",
      "Dataset shape: (4800, 25)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/fewshot/accept_res_outlines_Qwen2.5-0.5B-Instruct_cleaned.tsv\n",
      "Processing model: qwen5\n",
      "Dataset shape: (4800, 25)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/fewshot/accept_res_outlines_Qwen2.5-1.5B-Instruct_cleaned.tsv\n",
      "Processing model: qwen3\n",
      "Dataset shape: (4800, 25)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/fewshot/accept_res_outlines_Qwen2.5-3B-Instruct_cleaned.tsv\n",
      "Processing model: qwen14\n",
      "Dataset shape: (4800, 25)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/fewshot/accept_few_Qwen2.5-14B-Instruct_cleaned.tsv\n",
      "Processing model: qwen32\n",
      "Dataset shape: (4800, 25)\n",
      "Processing complete. Total cleaned acceptability ratings: 4800\n",
      "Cleaned results saved to: ../../data/res/acceptability/fewshot/accept_few_Qwen2.5-32B-Instruct_cleaned.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "acc_few_dict = {\"falcon\" : \"../../data/res/acceptability/fewshot/accept_res_outlines_falcon-7b-instruct.tsv\",\n",
    "\"gemma\" : \"../../data/res/acceptability/fewshot/accept_res_outlines_gemma-2-9b-it.tsv\",\n",
    "\"gpt4omini\" : \"../../data/res/acceptability/fewshot/accept_res_outlines_gpt-4o-mini_few.tsv\",\n",
    "\"gpt4o\" : \"../../data/res/acceptability/fewshot/accept_res_outlines_gpt-4o_few.tsv\",\n",
    "\"llama\" : \"../../data/res/acceptability/fewshot/accept_res_outlines_Meta-Llama-3.1-8B-Instruct.tsv\",\n",
    "\"mistral\" : \"../../data/res/acceptability/fewshot/accept_res_outlines_Mistral-7B-Instruct-v0.3.tsv\",\n",
    "\"qwen\" : \"../../data/res/acceptability/fewshot/accept_res_outlines_Qwen2.5-7B-Instruct.tsv\" }\n",
    "\n",
    "clean_results(\"acc_few\", acc_few_dict)\n",
    "\n",
    "###########*******\n",
    "\n",
    "acc_zero_dict = {\"falcon\" : \"../../data/res/acceptability/zeroshot/accept_res_outlines_falcon-7b-instruct.tsv\",\n",
    "\"gemma\" : \"../../data/res/acceptability/zeroshot/accept_res_outlines_gemma-2-9b-it.tsv\",\n",
    "\"gpt4omini\" : \"../../data/res/acceptability/zeroshot/accept_res_outlines_gpt-4o-mini_zero.tsv\",\n",
    "\"gpt4o\" : \"../../data/res/acceptability/zeroshot/accept_res_outlines_gpt-4o_zero.tsv\",\n",
    "\"llama\" : \"../../data/res/acceptability/zeroshot/accept_res_outlines_Meta-Llama-3.1-8B-Instruct.tsv\",\n",
    "\"mistral\" : \"../../data/res/acceptability/zeroshot/accept_res_outlines_Mistral-7B-Instruct-v0.3.tsv\",\n",
    "\"qwen\" : \"../../data/res/acceptability/zeroshot/accept_res_outlines_Qwen2.5-7B-Instruct.tsv\" }\n",
    "\n",
    "clean_results(\"acc_zero\", acc_zero_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "acc_qwen = {\"qwen05\" : \"../../data/res/acceptability/fewshot/accept_res_outlines_Qwen2.5-0.5B-Instruct.tsv\",\n",
    "\"qwen5\" : \"../../data/res/acceptability/fewshot/accept_res_outlines_Qwen2.5-1.5B-Instruct.tsv\",\n",
    "\"qwen3\" : \"../../data/res/acceptability/fewshot/accept_res_outlines_Qwen2.5-3B-Instruct.tsv\",\n",
    "\"qwen14\": \"../../data/res/acceptability/fewshot/accept_few_Qwen2.5-14B-Instruct.tsv\",\n",
    "\"qwen32\": \"../../data/res/acceptability/fewshot/accept_few_Qwen2.5-32B-Instruct.tsv\"}\n",
    "\n",
    "clean_results(\"acc_qwen\", acc_qwen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd7c01c",
   "metadata": {},
   "source": [
    "## Cloze-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f14c7061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Processing Task: cloze_few\n",
      "Processing model: falcon\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/fewshot/cloze_res_outlines_falcon-7b-instruct_cleaned.tsv\n",
      "Processing model: gemma\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/fewshot/cloze_res_outlines_gemma-2-9b-it_cleaned.tsv\n",
      "Processing model: gpt4omini\n",
      "Dataset shape: (1200, 10)\n",
      "Dataset shape before processing: (1200, 10)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/fewshot/cloze_res_outlines_gpt-4o-mini_few_cleaned.tsv\n",
      "Processing model: llama\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/fewshot/cloze_res_outlines_Meta-Llama-3.1-8B-Instruct_cleaned.tsv\n",
      "Processing model: mistral\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/fewshot/cloze_res_outlines_Mistral-7B-Instruct-v0.3_cleaned.tsv\n",
      "Processing model: qwen\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Error: Multiple different conjunctions detected: {'because', 'after'}. Case: Conflicting conjunctions in response because after because\n",
      "Error: Multiple different conjunctions detected: {'then', 'so'}. Case: Conflicting conjunctions in response so then because\n",
      "Error: Multiple different conjunctions detected: {'because', 'after'}. Case: Conflicting conjunctions in response because after because\n",
      "Error: Multiple different conjunctions detected: {'because', 'after'}. Case: Conflicting conjunctions in response because after because\n",
      "Error: Multiple different conjunctions detected: {'then', 'because'}. Case: Conflicting conjunctions in response because then because\n",
      "Error: Multiple different conjunctions detected: {'because', 'after'}. Case: Conflicting conjunctions in response because after because\n",
      "Error: Multiple different conjunctions detected: {'then', 'because'}. Case: Conflicting conjunctions in response because then because\n",
      "Error: Multiple different conjunctions detected: {'then', 'because'}. Case: Conflicting conjunctions in response because then because\n",
      "Error: Multiple different conjunctions detected: {'because', 'after'}. Case: Conflicting conjunctions in response because after because\n",
      "Error: Multiple different conjunctions detected: {'then', 'because'}. Case: Conflicting conjunctions in response because then after\n",
      "Error: Multiple different conjunctions detected: {'because', 'after'}. Case: Conflicting conjunctions in response because after because\n",
      "Error: Multiple different conjunctions detected: {'then', 'because'}. Case: Conflicting conjunctions in response because then after\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/fewshot/cloze_res_outlines_Qwen2.5-7B-Instruct_cleaned.tsv\n",
      "Processing model: gpt4o\n",
      "Dataset shape: (1200, 10)\n",
      "Dataset shape before processing: (1200, 10)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/fewshot/cloze_res_outlines_gpt-4o_few_cleaned.tsv\n",
      "**** Processing Task: cloze_zero\n",
      "Processing model: falcon\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/zeroshot/cloze_res_outlines_falcon-7b-instruct_cleaned.tsv\n",
      "Processing model: gemma\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/zeroshot/cloze_res_outlines_gemma-2-9b-it_cleaned.tsv\n",
      "Processing model: gpt4omini\n",
      "Dataset shape: (1200, 10)\n",
      "Dataset shape before processing: (1200, 10)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/zeroshot/cloze_res_outlines_gpt-4o-mini_zero_cleaned.tsv\n",
      "Processing model: gpt4o\n",
      "Dataset shape: (1200, 10)\n",
      "Dataset shape before processing: (1200, 10)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/zeroshot/cloze_res_outlines_gpt-4o_zero_cleaned.tsv\n",
      "Processing model: llama\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Error: Multiple different conjunctions detected: {'because', 'then'}. Case: Conflicting conjunctions in response # then\n",
      "because the\n",
      "Error: Multiple different conjunctions detected: {'because', 'then'}. Case: Conflicting conjunctions in response # then\n",
      "because diana\n",
      "Error: Multiple different conjunctions detected: {'because', 'so'}. Case: Conflicting conjunctions in response so\n",
      "because\n",
      "after\n",
      "Error: Multiple different conjunctions detected: {'because', 'then'}. Case: Conflicting conjunctions in response # then\n",
      "because the\n",
      "Error: Multiple different conjunctions detected: {'because', 'so'}. Case: Conflicting conjunctions in response so\n",
      "because\n",
      "after\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/zeroshot/cloze_res_outlines_Meta-Llama-3.1-8B-Instruct_cleaned.tsv\n",
      "Processing model: mistral\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/zeroshot/cloze_res_outlines_Mistral-7B-Instruct-v0.3_cleaned.tsv\n",
      "Processing model: qwen\n",
      "Dataset shape: (1200, 11)\n",
      "Dataset shape before processing: (1200, 11)\n",
      "Total responses received: 1200\n",
      "Processing complete. Total cleaned cloze test responses: 1200\n",
      "Cleaned results saved to: ../../data/res/cloze/zeroshot/cloze_res_outlines_Qwen2.5-7B-Instruct_cleaned.tsv\n"
     ]
    }
   ],
   "source": [
    "###########*******\n",
    "\n",
    "\n",
    "cloze_few_dict = {\n",
    "    \"falcon\": \"../../data/res/cloze/fewshot/cloze_res_outlines_falcon-7b-instruct.tsv\",\n",
    "    \"gemma\": \"../../data/res/cloze/fewshot/cloze_res_outlines_gemma-2-9b-it.tsv\",\n",
    "    \"gpt4omini\": \"../../data/res/cloze/fewshot/cloze_res_outlines_gpt-4o-mini_few.tsv\",\n",
    "    \"llama\": \"../../data/res/cloze/fewshot/cloze_res_outlines_Meta-Llama-3.1-8B-Instruct.tsv\",\n",
    "    \"mistral\": \"../../data/res/cloze/fewshot/cloze_res_outlines_Mistral-7B-Instruct-v0.3.tsv\",\n",
    "    \"qwen\": \"../../data/res/cloze/fewshot/cloze_res_outlines_Qwen2.5-7B-Instruct.tsv\",\n",
    "    \"gpt4o\": \"../../data/res/cloze/fewshot/cloze_res_outlines_gpt-4o_few.tsv\",\n",
    "}\n",
    "\n",
    "\n",
    "clean_results(\"cloze_few\", cloze_few_dict)\n",
    "\n",
    "###########*******\n",
    "\n",
    "\n",
    "cloze_zero_dict = {\n",
    "    \"falcon\": \"../../data/res/cloze/zeroshot/cloze_res_outlines_falcon-7b-instruct.tsv\",\n",
    "    \"gemma\": \"../../data/res/cloze/zeroshot/cloze_res_outlines_gemma-2-9b-it.tsv\",\n",
    "    \"gpt4omini\": \"../../data/res/cloze/zeroshot/cloze_res_outlines_gpt-4o-mini_zero.tsv\",\n",
    "    \"gpt4o\": \"../../data/res/cloze/zeroshot/cloze_res_outlines_gpt-4o_zero.tsv\",\n",
    "    \"llama\": \"../../data/res/cloze/zeroshot/cloze_res_outlines_Meta-Llama-3.1-8B-Instruct.tsv\",\n",
    "    \"mistral\": \"../../data/res/cloze/zeroshot/cloze_res_outlines_Mistral-7B-Instruct-v0.3.tsv\",\n",
    "    \"qwen\": \"../../data/res/cloze/zeroshot/cloze_res_outlines_Qwen2.5-7B-Instruct.tsv\"\n",
    "}\n",
    "\n",
    "\n",
    "clean_results(\"cloze_zero\", cloze_zero_dict)\n",
    "\n",
    "\n",
    "###########*******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02424ef1-67e3-46ff-821f-b1d6cc211f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explica",
   "language": "python",
   "name": "explica"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
